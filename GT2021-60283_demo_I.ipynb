{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GT2021-60283 Demo I - Load and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LF_file = \"data/NTNU_LF.h5\"\n",
    "HF_files = glob.glob(\"data/*kW.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.HDFStore(LF_file, 'r') as store:\n",
    "    LF_df = store.get(\"LF0000\")\n",
    "LF_df['orig_idx'] = LF_df.index\n",
    "for i, HF_file in enumerate(HF_files):\n",
    "    key = HF_file.split('//')[-1].split('.')[0]\n",
    "    with pd.HDFStore(HF_file, 'r') as store:\n",
    "        if i ==0:\n",
    "            HF_df = store.get(\"T0000\")\n",
    "            HF_df['key'] = key.split('\\\\')[-1]\n",
    "        else:\n",
    "            temp_HF = store.get(\"T0000\")\n",
    "            temp_HF['key'] = key.split('\\\\')[-1]\n",
    "            HF_df = HF_df.append(temp_HF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import welch\n",
    "def slice_signal(signal, time_window=4000, stepsize=100, rolling=True,\n",
    "                 pad_front=True):\n",
    "    # Split the timeseries into a 2d vector of time windows each of which\n",
    "    # will have the Hurst exponent evaluated\n",
    "    sig = np.array(signal).reshape(-1,)\n",
    "    if rolling:\n",
    "        # Pad the timeseries and then create a new array where each row is a\n",
    "        # step of a rolling window across the signal\n",
    "        if pad_front:\n",
    "            padded_sig = np.pad(sig, (time_window, 0), 'constant')\n",
    "        else:\n",
    "            padded_sig = np.pad(sig, (0, time_window), 'constant')\n",
    "        new_sig = np.zeros((int(np.ceil(sig.shape[0]/ stepsize)),\n",
    "                                             time_window))\n",
    "\n",
    "        try:\n",
    "            for i in range(time_window):\n",
    "                new_sig[:, i] = padded_sig[i:-(time_window-i):stepsize]\n",
    "        except:\n",
    "            for i in range(time_window):\n",
    "                new_sig[:, i] = padded_sig[i:-(time_window-i):stepsize][:-1]\n",
    "        K = new_sig.shape[0]\n",
    "\n",
    "    else:\n",
    "        K = np.floor_divide(sig.shape[0], time_window)\n",
    "        new_sig = sig[:int(K*time_window)].reshape(K, time_window)\n",
    "        assert(new_sig.shape == (K, time_window))\n",
    "\n",
    "\n",
    "    return new_sig\n",
    "def gen_welch(HF_df, col, LF_df, sample_length=8192, fs=50000):\n",
    "\n",
    "    raw_sig = slice_signal(HF_df[col].values, time_window=sample_length, stepsize=200)\n",
    "    f, Px1 = welch(raw_sig[0, :], fs = fs, nperseg=512, noverlap=80, detrend = 'linear', scaling = 'spectrum', return_onesided=True)\n",
    "    welch_dicts = []\n",
    "    welch_labels = [\"{}_welch_{}\".format(col, freq) for freq in f[:len(f)//2]]\n",
    "    welch_data = np.zeros((raw_sig.shape[0], len(welch_labels)))\n",
    "    for i in range(raw_sig.shape[0]):\n",
    "        temp_sig = raw_sig[i, :]\n",
    "        f, wel = welch(temp_sig, fs = fs, nperseg=512, noverlap=80, detrend = 'linear', scaling = 'spectrum', return_onesided=True)\n",
    "        welch_data[i, :] = np.abs(wel)[:len(wel)//2]\n",
    "    welch_df = pd.DataFrame(HF_df['TIME'].values[::200], columns=['TIME'])\n",
    "    welch_df = welch_df.assign(**dict.fromkeys(welch_labels, 0))\n",
    "    welch_df[welch_labels] = welch_data\n",
    "    welch_df['orig_idx'] = LF_df['orig_idx'].values\n",
    "    welch_df = welch_df.set_index('orig_idx', drop=False)\n",
    "    \n",
    "    return welch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in HF_df['key'].unique():\n",
    "    temp_df = HF_df[HF_df['key']==key]\n",
    "    temp_welch = gen_welch(temp_df, 'upper_mic_theta_000', LF_df[LF_df['key']==key])\n",
    "    with pd.HDFStore('data/{}_welch.h5'.format(key)) as store:\n",
    "        store.put(\"T0000\", temp_welch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
