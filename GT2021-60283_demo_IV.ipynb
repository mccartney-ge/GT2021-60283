{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GT2021-60283 Demo IV - Tune BNN with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import layers, Model, Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "#from dynamicsML.NN import Tuner, setup_NN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from subprocess import Popen\n",
    "import seaborn as sns\n",
    "import random\n",
    "import time\n",
    "import psutil as ps\n",
    "import glob\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook runs the `BNN_train.py` script with different combinations of hidden layers, hidden layer neurons and learning rates in order to tune the BNN on the given data. Random selections of hidden layers an hidden layer nueons will be made and then the learning rate will be decreased until the minimum loss occurs after 200 epochs. After each trial the history will be saved and loaded into a summary data frame which will track the trials ad can be used to find the optimum combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_running():\n",
    "    running = []\n",
    "    for proc in ps.process_iter():\n",
    "        try:\n",
    "            if 'BNN_train.py' in proc.cmdline():\n",
    "                run_no = proc.cmdline()[-4]\n",
    "                if run_no not in running:\n",
    "                    running.append(run_no)\n",
    "        except:\n",
    "            pass\n",
    "    return running\n",
    "def run_trial(num_hidden, num_neurons, indep_div, lr, run_id, single_run_mode=False, NNs=8, gpu=True, dataset_name=\"NTNU0000_FFT\", simultaneous=2):\n",
    "    #Call the BNN training with the hyperparams\n",
    "    DETACHED_PROCESS = 0x00000008\n",
    "    completed = False\n",
    "    while not completed:\n",
    "        instances = 0\n",
    "        for proc in ps.process_iter():\n",
    "            try:\n",
    "                if 'BNN_train.py' in proc.cmdline():\n",
    "                    if not single_run_mode or proc.cmdline()[-2] == run_id:\n",
    "                        instances += 1\n",
    "            except:\n",
    "                pass\n",
    "        if instances == 0:\n",
    "            completed = True\n",
    "        else:\n",
    "            time.sleep(1)\n",
    "    num_running=0\n",
    "    for m in range(NNs):\n",
    "        num_running = len(get_running())\n",
    "        while num_running >= simultaneous:\n",
    "            num_running = len(get_running())\n",
    "            time.sleep(1)\n",
    "        \n",
    "        cmd = ['D:\\\\Users\\\\212687364\\\\.virtualenvs\\\\LEAPGPU\\\\Scripts\\\\python.exe',\n",
    "               'BNN_train.py',\n",
    "               str(num_hidden),\n",
    "               str(num_neurons),\n",
    "               str(indep_div),\n",
    "               '{:.0e}'.format(lr),\n",
    "               str(m),\n",
    "               dataset_name,\n",
    "               run_id,\n",
    "               str(gpu)\n",
    "              ]\n",
    "        p = Popen(cmd)#,shell=False,stdin=None,stdout=None,stderr=None,close_fds=True,creationflags=DETACHED_PROCESS)\n",
    "    # Wait for all instances of BNN_train.py to complete\n",
    "    running=[]\n",
    "    completed = False\n",
    "    while not completed:\n",
    "        instances = 0\n",
    "        for proc in ps.process_iter():\n",
    "            try:\n",
    "                if 'BNN_train.py' in proc.cmdline():\n",
    "                    if not single_run_mode or proc.cmdline()[-2] == run_id:\n",
    "                        instances += 1\n",
    "            except:\n",
    "                pass\n",
    "        if instances == 0:\n",
    "            completed = True\n",
    "        else:\n",
    "            time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_trial(num_hidden, num_neurons, lr, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 1000\n",
    "trial_summaries = []\n",
    "for trial_no in range(5, num_trials):\n",
    "    \n",
    "    run_id = \"{:04d}\".format(trial_no)\n",
    "    print(run_id)\n",
    "    # Select hyperparams\n",
    "    num_hidden = random.randint(2, 10)\n",
    "    num_neurons = random.randint(10, 50)\n",
    "    indep_div = random.randint(200, 300)\n",
    "    lr = 1e-4\n",
    "    \n",
    "    run_trial(num_hidden, num_neurons,indep_div, lr, run_id, dataset_name=\"NN0042_meas\", gpu=False, simultaneous=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "trials = []\n",
    "for trial_no in range(1000):\n",
    "    \n",
    "    trial_dict= {'run_no':\"{:04d}\".format(trial_no)}\n",
    "    # Select hyperparams\n",
    "    trial_dict['num_hidden'] = random.randint(2, 10)\n",
    "    trial_dict['num_neurons'] = random.randint(10, 250)\n",
    "    trial_dict['indep_div'] = random.randint(200, 800)\n",
    "    lr_exp=random.randint(3, 6)\n",
    "    trial_dict['lr'] = 10**-lr_exp\n",
    "    trials.append(trial_dict)\n",
    "    #run_trial(trial_dict['num_hidden'], trial_dict['num_neurons'],\n",
    "    #                                   trial_dict['indep_div'], trial_dict['lr'], trial_dict['run_no'],\n",
    "    #                                   single_run_mode=True, NNs=1, gpu=False)\n",
    "Parallel(n_jobs=8)(delayed(run_trial)(trial_dict['num_hidden'], trial_dict['num_neurons'],\n",
    "                                       trial_dict['indep_div'], trial_dict['lr'], trial_dict['run_no'],\n",
    "                                       single_run_mode=False, NNs=8, gpu=True,\n",
    "                                      dataset_name='NN0042_X_DFA') for trial_dict in trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_id = 'NTNU0000_FFT'\n",
    "curr_model = None\n",
    "\n",
    "trial_summaries = []\n",
    "trial_dfs = {}\n",
    "for i, folder in enumerate(glob.glob(\"BNN_tuning/{}*\".format(data_id))):\n",
    "    print(i)\n",
    "    run_id = \"{:04d}\".format(i)\n",
    "    hidden_pos = folder.split('_').index('hidden')+1\n",
    "    stem = \"\"\n",
    "    for val in folder.split('_')[:hidden_pos-1]:\n",
    "        stem += val+'_'\n",
    "    run_id = stem.split(\"\\\\\")[1][:-1]\n",
    "    num_hidden = int(folder.split('_')[hidden_pos])\n",
    "    num_neurons = int(folder.split('_')[hidden_pos+2])\n",
    "    lr = float(folder.split('_')[hidden_pos+4])\n",
    "    #curr_model = load_BNN_dict(data_id, LF_df, num_hidden, num_neurons, lr, run_id, model_dict=curr_model)\n",
    "    #test_loglosses, short_ll, long_ll = get_BNN_loglosses(*[None]*6, curr_model, return_short_long=True, test_souce='X_val')\n",
    "    \n",
    "    histories = []\n",
    "    run_files = glob.glob(\"{}/*_hist.csv\".format(folder))\n",
    "    temp_summary = {'id':run_id, 'num_hidden':num_hidden, 'num_neurons':num_neurons, 'learning_rate':lr, 'n_ensemble':len(run_files)}\n",
    "    val_ll = []\n",
    "    train_ll = []\n",
    "    for m, file in enumerate(run_files):\n",
    "        run_hist = pd.read_csv(file)\n",
    "        temp_summary['run_length_{}'.format(m)] = len(run_hist)\n",
    "        temp_summary['min_val_logloss_{}'.format(m)] = np.min(run_hist['val_binary_crossentropy'].values)\n",
    "        val_ll.append(np.min(run_hist['val_binary_crossentropy'].values))\n",
    "        temp_summary['min_train_logloss_{}'.format(m)] = np.min(run_hist['binary_crossentropy'].values)\n",
    "        train_ll.append(np.min(run_hist['binary_crossentropy'].values))\n",
    "        temp_summary['hist_file_{}'.format(m)] = file\n",
    "        trial_dfs[\"{}_{}\".format(run_id, m)] = run_hist\n",
    "    temp_summary['avg_val_binary_crossentropy'] = np.mean(val_ll)\n",
    "    #temp_summary['en_short_val_binary_crossentropy'] = np.mean(short_ll)\n",
    "    #temp_summary['en_long_val_binary_crossentropy'] = np.mean(long_ll)\n",
    "    temp_summary['avg_train_binary_crossentropy'] = np.mean(train_ll)\n",
    "    #print(\"Logloss: {:.3f} \\t Short Logloss: {:.3f} \\t Long Logloss: {:.3f} \\t\".format(np.mean(val_ll), short_ll, long_ll))\n",
    "    trial_summaries.append(temp_summary)\n",
    "summary_df = pd.DataFrame(trial_summaries)\n",
    "\n",
    "summary_df[['id', 'num_hidden', 'num_neurons', 'learning_rate', 'n_ensemble', 'avg_train_binary_crossentropy','avg_val_binary_crossentropy',\n",
    "            #'en_short_val_binary_crossentropy', 'en_long_val_binary_crossentropy',\n",
    "            'hist_file_0']].sort_values('avg_val_binary_crossentropy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
